import streamlit as st
from PIL import Image as PILImage
import numpy as np
import cv2
from ultralytics import YOLO
import os
import time
import requests
from collections import Counter
from io import BytesIO

# Load model from GitHub if not present
@st.cache_resource
# Load model from Google Drive if not present
@st.cache_resource
def load_model():
    model_url = "https://drive.google.com/uc?export=download&id=1eE1BocN7wiTfMuZAxSPmcktuU-7F765F"
    model_path = "ishaan_model.pt"

    if not os.path.exists(model_path):
        with st.spinner("üîÑ Downloading model..."):
            try:
                import urllib.request
                urllib.request.urlretrieve(model_url, model_path)
                st.success("‚úÖ Model downloaded successfully.")
            except Exception as e:
                st.error(f"‚ùå Failed to download model: {e}")
                return None

    model = YOLO(model_path)
    return model


model = load_model()

# Object detection function
def detect_objects(image, selected_classes, conf_thresh):
    if model is None:
        return np.array(image), None

    results = model(image)
    img_np = np.array(image)
    detected_classes = []

    colors = {"crater": (0, 255, 0), "boulder": (255, 0, 0)}

    for r in results:
        boxes = r.boxes.xyxy.cpu().numpy()
        class_ids = r.boxes.cls.cpu().numpy().astype(int)
        confidences = r.boxes.conf.cpu().numpy()

        for box, class_id, conf in zip(boxes, class_ids, confidences):
            if conf < conf_thresh:
                continue

            class_name = model.names[class_id] if hasattr(model, 'names') else str(class_id)
            if selected_classes and class_name not in selected_classes:
                continue

            detected_classes.append(class_name)
            x1, y1, x2, y2 = map(int, box)
            color = colors.get(class_name, (255, 255, 0))
            label = f"{class_name} {conf:.2f}"

            cv2.rectangle(img_np, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img_np, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    if detected_classes:
        class_counts = Counter(detected_classes)
        st.write("### üìå Detected Object Counts:")
        for cls, count in class_counts.items():
            st.write(f"- {cls}: {count}")
    else:
        st.warning("‚ö†Ô∏è No objects detected with current settings.")

    pil_img = PILImage.fromarray(img_np)
    return img_np, pil_img

# Sidebar
st.sidebar.title("üîß Settings")
nav = st.sidebar.radio("Navigate", ["Home", "Detect", "Report"])

if model:
    st.sidebar.success("‚úÖ Model loaded successfully")
else:
    st.sidebar.error("‚ùå Model not loaded")

# ---- Home ----
if nav == "Home":
    st.title("üåï Lunar Vision: Crater & Boulder Detection")
    st.markdown("---")
    st.image("https://images-assets.nasa.gov/image/PIA02442/PIA02442~orig.jpg",
             caption="Apollo 17 ‚Äì Lunar Surface View (NASA)", use_container_width=True)

    st.subheader("üöÄ Mission Overview")
    st.markdown("""
    Welcome to **Lunar Vision**, your intelligent interface for **automated crater and boulder detection** 
    on high-resolution lunar surface imagery.

    This tool is developed as part of the **SOI Data Science Challenge 2025** and leverages a trained deep learning model to:
    - üß† Automatically detect surface features
    - üìç Assist space missions in planning safe routes and identifying scientific sites
    - üåü Enable real-time analysis from satellite or rover feeds
    """)

    st.subheader("‚ú® Features & Innovations")
    st.markdown("""
    ‚úÖ **YOLO-based detection model** optimized for lunar terrain  
    ‚úÖ **Real-time UI** ‚Äì Upload and detect features with a click  
    ‚úÖ **Customizable confidence threshold**  
    ‚úÖ **Multi-class selection:** Detect only craters, boulders, or both  
    ‚úÖ **Downloadable output** 
    """)

    st.subheader("üß™ Bonus Features for Extra Credit")
    st.markdown("""
    üí° **1. Instant Detection Interface**  
    Upload a lunar image on the **Detect** tab, bounding boxes generate with minimal clicks.

    üåç **2. Mission Planning & Rover Navigation Use**  
    - Generate safe zone maps  
    - Assist rovers in **path planning** using detections
    """)

    st.subheader("üìö How to Use This App")
    st.markdown("""
    - Go to **Detect** ‚Üí Upload a lunar image and click **Detect Now**  
    - Adjust detection confidence and filter classes  
    - View/download detection results  
    - See reports and insights in **Report** tab
    """)

# ---- Detect ----
elif nav == "Detect":
    st.title("üöÅ Detect Lunar Features")
    uploaded_file = st.file_uploader("üìÇ Upload a Lunar Image", type=["jpg", "jpeg", "png"])
    conf_threshold = st.sidebar.slider("Confidence Threshold", 0.0, 1.0, 0.5, 0.05)

    if model and hasattr(model, "names"):
        class_list = list(model.names.values())
        selected_classes = st.sidebar.multiselect("Classes to detect", class_list, default=class_list)
    else:
        selected_classes = []

    if uploaded_file:
        image = PILImage.open(uploaded_file).convert("RGB")
        resize_slider = st.slider("Resize image display %", 10, 100, 100)
        new_size = (int(image.width * resize_slider / 100), int(image.height * resize_slider / 100))
        st.image(image.resize(new_size), caption="üì∑ Uploaded Image", use_container_width=True)

        if st.button("üöÄ Detect Now"):
            with st.spinner("Detecting..."):
                progress = st.progress(0)
                for i in range(100):
                    time.sleep(0.005)
                    progress.progress(i + 1)

                result_img, result_pil = detect_objects(image, selected_classes, conf_threshold)
                st.success("‚úÖ Detection Completed")
                st.image(result_img, caption="üß† Detected Features", use_container_width=True)

                buf = BytesIO()
                result_pil.save(buf, format="PNG")
                st.download_button("üìÖ Download Detected Image", buf.getvalue(), file_name="lunar_detection.png", mime="image/png")

# ---- Report ----
elif nav == "Report":
    st.title("üìä Detection Report")
    st.markdown("---")
    st.subheader("üß† Model Decision Explanation")
    st.markdown("""
    Our YOLO-based model identifies craters and boulders by learning patterns in edges, contrast, and textures specific to lunar terrain.

    - **Craters**: Usually detected by circular depressions with shadow boundaries.  
    - **Boulders**: Identified as sharp-edged, high-contrast objects casting shadows.

    In future, **Grad-CAM** or **attention maps** will help explain which parts of the image influenced each prediction.
    """)
